# For multimodal experiment
# Take an elan file of the video, with a tier called 'synch' with two annotations:
# "player 1 start" and "player 2 start", which marks the start of the audio of the web program.
# And also take the csv file generated by the program
# add annotations to the elan file to mark out trial boundaries.

# Requires pympi.   https://github.com/dopefishh/pympi


import pympi
import glob
import sys

turnmargin = 100



eaffolder = '../data/eafWithSynchTier/'
destinationFolder = '../data/eafWithTrials'


def loadCSV(filename):
	o = open(filename)
	trials = o.read()
	o.close()
	trials =  [x.split(",") for x in trials.replace('"',"").replace("\r","").split("\n") if len(x)>1]
	header = trials[0]
	trials = trials[1:]
	return trials, header



for eafpath in glob.glob(eaffolder+'*.eaf'):

	filename = eafpath[eafpath.rindex("/"):eafpath.rindex(".")]

	eaffile = pympi.Eaf(eafpath)
	soundStart = eaffile.get_annotation_data_for_tier("synch")
	

	
	for player in ["1"]:#,"2"]:
		tierName = "Trials "+player
		eaffile.add_tier("Trials "+player)
		soundStartTime = int([x[0] for x in soundStart if x[2]=="player "+player+" start"][0])

		trials, header = loadCSV("../data/csvFromWebProgram/"+filename + "_player"+player+".csv")
		
		curTime = 0
		
		for t in trials:
			start = curTime
			end = int(t[header.index("timeSinceStart")]) + soundStartTime
			curTime = end
			value = t[header.index("choiceItem")]
			
			if value !="NextRound":
				tag = "#".join([t[header.index(x)] for x in ["game","stage"]])
				tag += "#" + str(int(t[header.index("currentTarget")])+1)
				tag += "#" + "_".join([str(int(x)+1) for x in t[header.index("currentDistractors")].split("_")])
				tag += "#" + str(int(t[header.index("choiceItem")])+1)
				eaffile.add_annotation(tierName, start, end, tag)
		
	eaffile.to_file("../data/eafWithTrialsTier/"+filename+"_TT"+".eaf")


	