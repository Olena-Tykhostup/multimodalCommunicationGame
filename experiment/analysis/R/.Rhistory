freq = length + valence + rnorm(n)
RT = valence
summary(lm(RT ~ length))
summary(lm(RT ~ length + freq))
n = 200
length = sample(1:7,n,replace = T)
valence = sample(1:7,n,replace = T)
freq = length + valence + rnorm(n)
RT = valence
summary(lm(RT ~ length))
summary(lm(RT ~ length + freq))
n = 200
length =  sample(1:7, n, replace = T)
valence = sample(1:7, n, replace = T)
freq = length + valence + rnorm(n)
RT = valence + rnorm(n)
summary(lm(RT ~ length))
summary(lm(RT ~ length + freq))
?system
system("python --version")
system("python3.5 --version")
250 + 360 + 120 + 220\
250 + 360 + 120 + 220
30 * 5
250 + 360 + 150 + 220
devtools::install_github("mdneuzerling/monstr")
library(monstr)
monstr::monsters$name
monsters$`Adult Black Dragon`
monster = monsters[monsters$name=="Adult Black Dragon",]
lines <- monster %>%
stringi::stri_split_lines(omit_empty = TRUE) %>%
unlist %>%
as_tibble %>% # much easier to deal with than lists
mutate_all(trimws) %>%
mutate_all(function(x) gsub("_", "", x)) # remove italics
print(lines, n = nrow(lines))
library(dplyr)
lines <- monster %>%
stringi::stri_split_lines(omit_empty = TRUE) %>%
unlist %>%
as_tibble %>% # much easier to deal with than lists
mutate_all(trimws) %>%
mutate_all(function(x) gsub("_", "", x)) # remove italics
print(lines, n = nrow(lines))
monster
View(monster)
---
title: "Simultaneity"
author: "Anita Slonimska"
date: "3/19/2019"
---
```{r setup, include=FALSE}
##load libraries
library(reshape2)
library(plyr)
library(lme4)
library(lattice)
library(scales)
library(ggplot2)
library(sjPlot)
library(Rmisc)
library(dplyr)
library(nlme)
library(optimx)
library(magrittr)
library (sicegar)
library(lmerTest)
library(RColorBrewer)
library(devtools)
library(piecewiseSEM)
library(MuMIn)
library(dplyr)
library(minqa)
d <- read.delim2("~/Downloads/masterfile_sign_R.txt")
#get the total number of simultaneous signs (movement segments)
d$simult_kinem <- (d$two_info+ d$three_info+d$four_info)
names(d)[names(d) == "movement_units"] <- "length"
#add column with unique trial - combination of animal pair and difficulty level -
#to account for per item variation later on
d$trial <- paste(d$Animal_pair, d$Diff_level, sep=",")
d$Diff_level[d$Diff_level == "1"] <- "D1"
d$Diff_level[d$Diff_level == "2"] <- "D2"
d$Diff_level[d$Diff_level == "3"] <- "D3"
d$Diff_level[d$Diff_level == "4"] <- "D4"
d$Diff_level[d$Diff_level == "5"] <- "D5"
d$Animal_pair <- as.factor(d$Animal_pair)
d$Diff_level <- as.factor(d$Diff_level)
d$trial <- as.factor(d$trial)
d$length <- as.numeric(d$length)
d$one_info <- as.numeric(d$one_info)
d$two_info <- as.numeric(d$two_info)
d$three_info <- as.numeric(d$three_info)
d$four_info <- as.numeric(d$four_info)
d$PartID <- as.factor(d$PartID)
d$Age <- as.numeric(d$Age)
d$Sex <- as.factor(d$Sex)
d$Hand <- as.factor(d$Hand)
#Each row in the data is a single response from a participant to a single sample. The key variables are:
# PartID: identifies participants
# trial: identifies unique trial
# Animal_pair: identifies character pairs used in stimuli
# Diff_level: the level of the difficulty of the trial
# length: length of the entire utterance for the trial quantified as total number of Movement Segments (MS) per trial
#OUTCOCOME VARIABLES:
#length: number of MS in total for each trial
#simult_total: proportion of movement segments containing kinematically simultaneous articulators encdoding distinct meaning (2 articulators or more)
#devided by total number of MS used for each trial
#2sim: proprtion of MS with 2 simultaneous information units
#devided by total number of MS containing simultaneous information units in a trial
#3sim: shows proprtion of MS with 3 simultaneous infoirmation units
#devided by total number of MS containing simultaneous information units in a trial
#4sim: shows proprtion of MS with 4 simultaneous information units
#devided by total number of MS containing simultaneous information units in a trial
#prepare data sets for further analyses for various simulatneous density (to accoutn for 2, 3 and 4 units in data)
d_D1_out = d[d$Diff_level!= "D1",]
d_D1D2_out = d_D1_out[d_D1_out$Diff_level!= "D2",]
d_D1D2D3_out = d_D1D2_out[d_D1D2_out$Diff_level!= "D3",]
```
mDiff = glmer(
length ~ 1 + Diff_level +
(1 | PartID) +
(1 | trial),
data = d,
family=poisson(link = "log")
)
summary(mDiff)
m0 = glmer(
length ~ 1 +
(1 | PartID) +
(1 | trial),
data = d,
family=poisson(link = "log")
)
anova(m0, mDiff)
table(d$PartID,d$Animal_pair)
table(d$PartID,d$Diff_level)
table(d$PartID,d$trial)
---
title: "Simultaneity"
author: "Anita Slonimska"
date: "3/19/2019"
---
```{r setup, include=FALSE}
##load libraries
library(reshape2)
library(plyr)
library(lme4)
library(lattice)
library(scales)
library(ggplot2)
library(sjPlot)
library(Rmisc)
library(dplyr)
library(nlme)
library(optimx)
library(magrittr)
library (sicegar)
library(lmerTest)
library(RColorBrewer)
library(devtools)
library(piecewiseSEM)
library(MuMIn)
library(dplyr)
library(minqa)
d <- read.delim2("~/Downloads/masterfile_sign_R.txt")
#get the total number of simultaneous signs (movement segments)
d$simult_kinem <- (d$two_info+ d$three_info+d$four_info)
names(d)[names(d) == "movement_units"] <- "length"
#add column with unique trial - combination of animal pair and difficulty level -
#to account for per item variation later on
d$trial <- paste(d$Animal_pair, d$Diff_level, sep=",")
d$Diff_level[d$Diff_level == "1"] <- "D1"
d$Diff_level[d$Diff_level == "2"] <- "D2"
d$Diff_level[d$Diff_level == "3"] <- "D3"
d$Diff_level[d$Diff_level == "4"] <- "D4"
d$Diff_level[d$Diff_level == "5"] <- "D5"
d$Animal_pair <- as.factor(d$Animal_pair)
d$Diff_level <- as.factor(d$Diff_level)
d$trial <- as.factor(d$trial)
d$length <- as.numeric(d$length)
d$one_info <- as.numeric(d$one_info)
d$two_info <- as.numeric(d$two_info)
d$three_info <- as.numeric(d$three_info)
d$four_info <- as.numeric(d$four_info)
d$PartID <- as.factor(d$PartID)
d$Age <- as.numeric(d$Age)
d$Sex <- as.factor(d$Sex)
d$Hand <- as.factor(d$Hand)
#Each row in the data is a single response from a participant to a single sample. The key variables are:
# PartID: identifies participants
# trial: identifies unique trial
# Animal_pair: identifies character pairs used in stimuli
# Diff_level: the level of the difficulty of the trial
# length: length of the entire utterance for the trial quantified as total number of Movement Segments (MS) per trial
#OUTCOCOME VARIABLES:
#length: number of MS in total for each trial
#simult_total: proportion of movement segments containing kinematically simultaneous articulators encdoding distinct meaning (2 articulators or more)
#devided by total number of MS used for each trial
#2sim: proprtion of MS with 2 simultaneous information units
#devided by total number of MS containing simultaneous information units in a trial
#3sim: shows proprtion of MS with 3 simultaneous infoirmation units
#devided by total number of MS containing simultaneous information units in a trial
#4sim: shows proprtion of MS with 4 simultaneous information units
#devided by total number of MS containing simultaneous information units in a trial
#prepare data sets for further analyses for various simulatneous density (to accoutn for 2, 3 and 4 units in data)
d_D1_out = d[d$Diff_level!= "D1",]
d_D1D2_out = d_D1_out[d_D1_out$Diff_level!= "D2",]
d_D1D2D3_out = d_D1D2_out[d_D1D2_out$Diff_level!= "D3",]
library(REEMtree)
?REEMtree(Diff_level,d,random=1|)
?REEMtree
head(d)
?REEMtree(Diff_level~sim2.p+sim3.p+sim4p,d,random=1|PartID + 1|trial)
t = REEMtree(Diff_level~sim2.p+sim3.p+sim4.p,d,random=1|PartID + 1|trial)
t = REEMtree(Diff_level~sim2.p+sim3.p+sim4.p,d,random=list(1|PartID, 1|trial))
t = REEMtree(Diff_level~sim2.p+sim3.p+sim4.p,d)
names(d)
d$sim2.p
# For some reason, the sim.p and other proportion fields are being
# converted to a factor. So convert back to a number:
d$sim.p = as.numeric(as.character(d$sim.p))
d$sim2.p = as.numeric(as.character(d$sim2.p))
d$sim3.p = as.numeric(as.character(d$sim3.p))
d$sim4.p = as.numeric(as.character(d$sim4.p))
t = REEMtree(Diff_level~sim2.p+sim3.p+sim4.p,d,random=list(1|PartID, 1|trial))
d$Diff_level
d$sim.p
d$sim2.p
d$sim3.p
d$sim4.p
t = REEMtree(Diff_level~sim2.p+sim3.p+sim4.p,d,random=1|PartID)
d$PartID
d$PartID = as.character(d$PartID)
t = REEMtree(Diff_level~sim2.p+sim3.p+sim4.p,d,random=1|PartID)
t = REEMtree(as.numeric(Diff_level)~sim2.p+sim3.p+sim4.p,d,random=1|PartID)
d$Diff_level=as.numeric(d$Diff_level)
t = REEMtree(Diff_level~sim2.p+sim3.p+sim4.p,d,random=1|PartID)
t = REEMtree(Diff_level~sim2.p+sim3.p+sim4.p,d[complete.cases(d),],random=1|PartID)
library(party)
t = ctree(Diff_level~sim2.p+sim3.p+sim4.p,d)
plot(t)
d$Diff_level = factor(d$Diff_level)
t = ctree(Diff_level~sim2.p+sim3.p+sim4.p,d)
plot(t)
?lmer
library(lme4)
?lmer
?glmer
?glm
r = function(){
max(sample(1:20, 2))
}
replicate(5,r)
r = function(){
return(max(sample(1:20, 2)))
}
replicate(5,r())
r = function(){
return(max(sample(1:20, 2)+4))
}
replicate(5,r())
r = function(){
return(max(sample(1:20, 2)+4))
}
replicate(5,r())
replicate(6,r())
replicate(6,r())
replicate(6,r())
try(setwd("~/Documents/Funding/InternationalStrategicFund/project/processing/"))
###
d = read.csv("../data/Sagart_etal_2019/Dhakal_and_Sagart_data_clustered.tsv",sep="\t",quote="",stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8", skip=3, comment.char = "#")
table(d[sel,]$COGID,d[sel,]$OLDCOG)
sel = d$CONCEPT==d$CONCEPT[1]
table(d[sel,]$COGID,d[sel,]$OLDCOG)
heatmap(table(d[sel,]$COGID,d[sel,]$OLDCOG))
sel = d$CONCEPT==unique(d$CONCEPT)[2]
heatmap(table(d[sel,]$COGID,d[sel,]$OLDCOG))
sel = d$CONCEPT==unique(d$CONCEPT)[3]
heatmap(table(d[sel,]$COGID,d[sel,]$OLDCOG))
sel = d$CONCEPT==unique(d$CONCEPT)[4]
heatmap(table(d[sel,]$COGID,d[sel,]$OLDCOG))
unique(d$CONCEPT)
sel = d$CONCEPT==unique(d$CONCEPT)[4]
sum(sel)
heatmap(table(d[sel,]$COGID,d[sel,]$OLDCOG))
table(d[sel,]$COGID,d[sel,]$OLDCOG)
sel = d$CONCEPT==unique(d$CONCEPT)[5]
heatmap(table(d[sel,]$COGID,d[sel,]$OLDCOG))
d$OLDCOG
sel = d$CONCEPT==unique(d$CONCEPT)[6]
heatmap(table(d[sel,]$COGID,d[sel,]$OLDCOG))
sel = d$CONCEPT==unique(d$CONCEPT)[7]
heatmap(table(d[sel,]$COGID,d[sel,]$OLDCOG))
ue(d$CONCEPT)))
names(res) = unique(d$CONCEPT)
for(con in unique(d$CONCEPT)){
sel = d$CONCEPT==con
tx = (table(d[sel,]$COGID,d[sel,]$OLDCOG))
res[con] = sum(apply(tx,1,function(X){sum(X)>0})==1)
}
res = rep(0,length(unique(d$CONCEPT)))
names(res) = unique(d$CONCEPT)
for(con in unique(d$CONCEPT)){
sel = d$CONCEPT==con
tx = (table(d[sel,]$COGID,d[sel,]$OLDCOG))
res[con] = sum(apply(tx,1,function(X){sum(X)>0})==1)
}
res
res = rep(0,length(unique(d$CONCEPT)))
names(res) = unique(d$CONCEPT)
for(con in unique(d$CONCEPT)){
sel = d$CONCEPT==con
tx = (table(d[sel,]$COGID,d[sel,]$OLDCOG))
res[con] = sum(apply(tx,1,function(X){sum(X)>0})==1)/nrow(tx)
}
hist(res)
res
tx
con = d$CONCEPT[1]
sel = d$CONCEPT==con
tx = (table(d[sel,]$COGID,d[sel,]$OLDCOG))
tx
sum(apply(tx,1,function(X){sum(X)>0})==1)
dim(tx)
sum(apply(tx,1,function(X){sum(X)>0})
apply(tx,1,function(X){sum(X)>0})
res[con] = sum(apply(tx,1,function(X){sum(X>0)})==1)/nrow(tx)
apply(tx,1,function(X){sum(X>0)})
res = rep(0,length(unique(d$CONCEPT)))
names(res) = unique(d$CONCEPT)
for(con in unique(d$CONCEPT)){
sel = d$CONCEPT==con
tx = (table(d[sel,]$COGID,d[sel,]$OLDCOG))
res[con] = sum(apply(tx,1,function(X){sum(X>0)})==1)/nrow(tx)
}
res
hist(res)
sum(res==1)/length(res)
?p.adjust
---
title: "Modality effects in a signalling game: Efficiency"
output:
pdf_document:
toc: true
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), "../../results/MainResults_Efficiency.pdf")) })
---
# Introduction
The main data used in this analysis comes from `../../data/FinalSignalData.csv` (compiled by  `analyseData.R`).  Each row represents one signal, but this script only keeps one signal per trial, and the rest of the analysis is on the trial-by-trial level.  The variables in the data are as follows (some are calculated in the script below):
-  X: ID
-  filename: Filename of the ELAN file
-  dyadNumber: ID of the participant dyad
-  condition: Stimuli type (Auditory or Visual)
-  game: Game number (0-3)
-  trial: Trial number (0-15)
-  target: Target stimuli shown to the director
-  choice: Meaning chosen by the matcher
-  correct: True if the matcher's choice is correct
-  trialStart, trialEnd, trialLength: Start, end and length of trial in milliseconds
-  trialValue:  A unique string that represents data from the trial.  Numbers in the curly brackets represent the choices given to the matcher
-  startOfNextTrial: Timestamp for next trial, used in processing the data.
-  turnStart, turnEnd, turnLength: the start, end and length of the turn in milliseconds.
-  signalStart, signalEnd, signalLength: the start, end and length of the signal.
-  signalType:  Annotation value in ELAN, not meaningful
-  tiralString: Unique string to identify trial
-  modalityCondition:  The condition for the dyad (multi= multimodal, visual=gesture only, vocal=vocal only)
-  playerId:  Unique ID for the participant producing the signal
-  itemId:  Unique ID for the target stimulus
-  turnString:  Unque ID for the turn
-  matcherResponds:  Does matcher take a turn in this trial?
-  matcherResponds.cumulative: The (scaled) number of previous trials that a has responded.
-  T1Length, T1Length.log:  Length and log length of the director's first turn.
-  trialTotal: Number of trials played so far, scaled (and centered) to represent number of games played.
-  firstBlock:  Block order
-  incorrect:  Was the matcher's choice incorrect?
-  multimodal:  Was the director's first turn multimodal?
## Load libraries
```{r warning=FALSE, message=FALSE}
library(lme4)
library(sjPlot)
library(ggplot2)
library(lattice)
#library(influence.ME)
library(dplyr)
```
The sjPlot library was updated during this investigation, removing various functions. They are reinstated here:
```{r}
sjp.lmer = plot_model
```
```{r echo=F}
try(setwd("~/Documents/MPI/ViniciusMultimodal/multimodalCommunicationGame/experiment/analysis/R/"))
```
## Load data
```{r}
d = read.csv("../../data/FinalSignalData.csv")
```
Variable for length of first T1
```{r}
T1L = tapply(d[d$turnType=="T1",]$turnLength,
d[d$turnType=="T1",]$trialString, head, n=1)
d$T1Length = T1L[d$trialString]
d$T1Length[is.na(d$T1Length)] = mean(d$T1Length,na.rm=T)
d$T1Length.log = log(d$T1Length)
d$T1Length.log = d$T1Length.log - mean(d$T1Length.log)
```
We don't need info on every signal in each turn, just the trial time.  Keep only 1st signal in each trial.
```{r}
d = d[!duplicated(d$trialString),]
```
# Descriptive stats
Make a variable to represent proportion of games played:
```{r}
# Make a variable that represents the number of trials played
d$trialTotal = d$trial + (d$game * (max(d$trial)+1))
# Convert to proportion of games played, so that estimates reflect change per game.
d$trialTotal = d$trialTotal / 16
```
Here is a graph showing the distribution of trial lengths by conditions:
```{r}
summary = d %>%
group_by(condition, modalityCondition,game) %>%
summarise(Efficiency=mean(trialLength),
sd=sd(trialLength),
ci.w =           qnorm(0.95)*sd/sqrt(length(trialLength)),
upper=Efficiency+ci.w,
lower = Efficiency-ci.w)
summary$game = summary$game +1
summary$modalityCondition =
factor(summary$modalityCondition,
levels = c("visual",'multi','vocal'),
labels=c("Gestural","Multimodal","Vocal"))
ggplot(d, aes(x=trialTotal, y=trialLength,colour=modalityCondition)) +
geom_smooth() + facet_grid(.~condition)
ggplot(d, aes(x=trialTotal, y=trialLength,colour=condition)) +
geom_smooth() + facet_grid(.~modalityCondition)
pd = position_dodge(width=0.5)
gx1 = ggplot(summary, aes(x=game, y=Efficiency, group=condition, colour=modalityCondition)) +
geom_errorbar(aes(ymin=lower, ymax=upper,group=modalityCondition), width=0.5,position=pd) +
facet_grid(. ~ condition) +
stat_summary(fun.y="mean", geom="line", aes(group=modalityCondition),position=pd) +
geom_point(aes(group=modalityCondition,shape=modalityCondition),position=pd) +
scale_colour_brewer(palette="Set2", name="Condition") +
scale_shape(name="Condition") +
theme(panel.grid.major.x = element_blank()) +
ggtitle("Efficiency") +
xlab("Game") +
ylab("Trial length (ms)")
gx1
pdf("../../results/graphs/Efficiency_gg.pdf",
width = 5, height=3)
gx1
dev.off()
gx2 = ggplot(summary, aes(x=game, y=Efficiency, group=condition, colour=condition, shape=condition)) +
geom_errorbar(aes(ymin=lower, ymax=upper), width=0.5) +
facet_grid(. ~ modalityCondition) +
stat_summary(fun.y="mean", geom="line", aes(group=condition)) +
geom_point() +
scale_colour_discrete(name="Stimuli") +
scale_shape_discrete(name="Stimuli") +
xlab("Game")
gx2
pdf("../../results/graphs/Efficiency_gg_alt.pdf",
width = 5, height=3)
gx2
dev.off()
```
![The efficiency of trials in different conditions](../../results/graphs/Efficiency.pdf)
Average trial time for the whole experiment:
```{r}
mean(d$trialLength)
sd(d$trialLength)
```
The distribution of trial times is very skewed:
```{r}
hist(d$trialLength)
```
So we transform it using a log transform, then center the data.
```{r}
d$trialLength.log = log(d$trialLength)
meanLogTrialLength = mean(d$trialLength.log)
d$trialLength.log = d$trialLength.log - meanLogTrialLength
hist(d$trialLength.log)
```
```{r}
# Center the trialTotal variable so intercept reflects after the first game
d$trialTotal = d$trialTotal - 2
matcherResponds.cumulative.mean = mean(d$matcherResponds.cumulative)
d$matcherResponds.cumulative = d$matcherResponds.cumulative - matcherResponds.cumulative.mean
d$matcherResponds = factor(d$matcherResponds)
```
Make a variable for which stimuli the players experienced first.
```{r}
firstBlock = tapply(as.character(d$condition),d$dyadNumber,head,n=1)
d$firstBlock = as.factor(firstBlock[match(d$dyadNumber,names(firstBlock))])
```
Reorder some levels so that the intercept reflects the most frequent condition.
```{r}
d$incorrect = !d$correct
```
Variable for whether T1 was a multimodal signal.
```{r}
turnD = read.csv("../../data/Final_Turn_data.csv")
turnD = turnD[turnD$turnType=="T1",]
turnD = turnD[turnD$role == "Director",]
d$multimodal = turnD[match(d$trialString, turnD$trialString),]$turnModalityType == "multi"
d$multimodal[is.na(d$multimodal)] = F
p.adjust(0.01,method="holm",5)
p.adjust(0.01,method="bonferroni",5)
p.adjust(0.01,method="bonferroni",6)
p.adjust(0.01,method="holm",6)
p.adjust(c(0.1,0.05,0.01,0.005,0.001),method="bonferroni",5)
p.adjust(c(0.1,0.05,0.01,0.005,0.001),method="holm",5)
