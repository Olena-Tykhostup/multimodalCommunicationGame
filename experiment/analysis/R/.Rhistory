d[,2] = d[,1]
ct=  ctree(formula(paste(v,"~ .")),
data = d,
controls = ctree_control(mincriterion = 0.99999))
plot(ct)
v = "V1"
plot(ct)
ct=  ctree(formula(paste(v,"~ .")),
data = d,
controls = ctree_control(mincriterion = 0.99999))
plot(ct)
where(ct)
length(unique(where(ct))
length(unique(where(ct)))
length(unique(where(ct)))
getBaseline = function(){
d = matrix(sample(c(0,1),69*91, replace=T), nrow=69, ncol=91)
d = as.data.frame(d)
# Count dependencies
dependencies = 0
# For each variable
for(v in names(d)){
# Get a deterministic binary tree
ct=  ctree(formula(paste(v,"~ .")),
data = d,
controls = ctree_control(mincriterion = 0.99999))
# Add number of terminal nodes -1
dependencies = dependencies +
(length(unique(where(ct))) -1)
}
return(dependencies)
}
getBaseline()
getBaseline = function(){
d = matrix(sample(c(0,1),69*91, replace=T), nrow=69, ncol=91)
d = as.data.frame(d)
# Count dependencies
dependencies = 0
# For each variable
for(v in names(d)){
# Get a deterministic binary tree
ct=  ctree(formula(paste(v,"~ .")),
data = d,
controls = ctree_control(mincriterion = 0.99999))
# Add number of terminal nodes -1
dependencies = dependencies +
(length(unique(where(ct))) -1)
}
return(dependencies)
}
baseline = replicate(getBaseline(),n = 100)
hist(baseline)
d[,2] = d[,1]
v = "V1"
ct=  ctree(formula(paste(v,"~ .")),
data = d,
controls = ctree_control(mincriterion = 0.99999))
(length(unique(where(ct))) -1)
table(baseline)
library(party)
getBaseline = function(){
d = matrix(sample(c(0,1),69*91, replace=T), nrow=69, ncol=91)
d = as.data.frame(d)
# Count dependencies
dependencies = 0
# For each variable
for(v in names(d)){
# Get a deterministic binary tree
ct=  ctree(formula(paste(v,"~ .")),
data = d,
controls = ctree_control(mincriterion = 0.99999))
# Add number of terminal nodes -1
dependencies = dependencies +
(length(unique(where(ct))) -1)
}
return(dependencies)
}
baseline = replicate(getBaseline(),n = 1000)
table(baseline)
d = matrix(sample(c(0,1),69*91, replace=T), nrow=69, ncol=91)
d = as.data.frame(d)
indoEuropean = d[1:38,]
otherLangs = d[39:ncol(d),]
apply(indoEuropean,2,function(X){
length(unique(X))==1
})
sum()
sum(apply(indoEuropean,2,function(X){
length(unique(X))==1
}))
getBaseline2 = function(){
d = matrix(sample(c(0,1),69*91, replace=T), nrow=69, ncol=91)
d = as.data.frame(d)
indoEuropean = d[1:38,]
otherLangs = d[39:ncol(d),]
commonIE = apply(indoEuropean,2,function(X){
length(unique(X))==1
})
sum(commonIE)
}
baseline2 = replicate(getBaseline2(),n = 1000)
table(baseline2)
9/69
1/69
load("~/Documents/MPI/CausalGraphs/ForDistribution/Data/WordData_scaled.Rdat")
ls()
dim(wd.nums)
names(wd.nums)
table(wd.nums$class)
rm(list=ls())
library(pcalg)
library(kpcalg)
library(mgcv)
library(parallel)
try(setwd("~/Documents/MPI/CausalGraphs/ForDistribution/Programs/KRFCI_Dummy/"))
source("rfci_keepTrackOfTests.r")
source("my_hsicgam.R")
# Load wd.nums
load("../../Data/WordData_scaled.Rdat")
wd.nums$noun = as.numeric(wd.nums$class=="N")
wd.nums$verb = as.numeric(wd.nums$class=="V")
wd.nums = wd.nums[,names(wd.nums)!="class"]
sapply(names(wd.nums),function(X){X=='class'})
library(mgcv)
try(setwd("~/Documents/Bristol/CHIELD/CHIELD_Online/processing/"))
d = read.csv("../data/db/CausalLinks.csv",stringsAsFactors = F)
dv1 = d[,c("Var1","bibref")]
dv2 = d[,c("Var2","bibref")]
names(dv2) = c("Var1",'bibref')
d = rbind(dv1,dv2)
cumUniqueVariables.mean = rep(0,length(unique(d$bibref)))
numSamples = 100
getCumUniqueVariables = function(){
docs = sample(unique(d$bibref))
d$bibref = factor(d$bibref,levels=docs)
d = d[order(d$bibref),]
# Cumulative unique variables
cumUniqueVariables =
sapply(docs,function(doc){
length(unique(d[1:max(which(d$bibref==doc)),]$Var1))
})
return(cumUniqueVariables)
}
cumUniqueVariables.mean = replicate(numSamples,getCumUniqueVariables())
cumUniqueVariables.mean = rowSums(cumUniqueVariables.mean)/numSamples
res = data.frame(
cumUniqueVariables.mean = cumUniqueVariables.mean,
numDocuments = 1:length(cumUniqueVariables.mean)
)
m0 = lm(cumUniqueVariables.mean~
numDocuments+
I(numDocuments^2),
data = res)
summary(m0)
newdata = data.frame(
numDocuments = 1:1000
)
predictedCurve = predict(m0,
newdata = data.frame(numDocuments = 1:3000))
dx = abs(diff(predictedCurve))
plateau = which(dx==min(dx))
newdata = data.frame(
numDocuments = seq(1,plateau,length.out=100)
)
predictedCurve = predict(m0,newdata = newdata)
plot(newdata$numDocuments,
predictedCurve,
xlab="Number of documents",
ylab="Number of unique variables",
type = 'l',
xlim=range(newdata$numDocuments),
ylim=c(0,max(predictedCurve)),
lty=2,col=2)
abline(0,1,lty=2)
points(1:length(cumUniqueVariables.mean),
cumUniqueVariables.mean,
xlab="Number of documents",
ylab="Number of unique variables",
type = 'l',lty=1,col=1,lwd=2)
old
# Change a variable
# Takes two arguments: oldVariable and newVariable
# Remember to use Rscript to run from command line
try(setwd("~/Documents/Bristol/CHIELD/CHIELD_Online/processing/"))
args = commandArgs(trailingOnly=TRUE)
if(length(args)!=2){
stop("2 arguments required (old and new variable label)")
}
oldVar = args[1]
newVar = args[2]
oldVar = "language deficits"
newVar = "specific language impairment"
treeBaseFolder = "../data/tree"
numChanged = 0
for(f in list.dirs(treeBaseFolder)){
files = list.files(f)
if(sum(grepl("*.csv",files))>0){
linkFile = files[grepl("*.csv",files)][1]
linkFilePos= paste0(f,"/",linkFile)
l <- read.csv(paste0(f,"/",linkFile), stringsAsFactors = F, encoding = 'utf-8',fileEncoding = 'utf-8')
chng = sum(l$Var1==oldVar,na.rm=T) + sum(l$Var2==oldVar,na.rm = T)
numChanged = numChanged + chng
if(chng>0){
l$Var1[l$Var1==oldVar] = l$Var1[l$Var1==newVar]
l$Var2[l$Var2==oldVar] = l$Var1[l$Var2==newVar]
write.csv(l,file=linkFilePos,fileEncoding = "UTF-8",row.names = F)
}
}
}
l
l$Var1==oldVar
sum(l$Var1==oldVar,na.rm=T) + sum(l$Var2==oldVar,na.rm = T)
l$Var1[l$Var1==oldVar]
library(mgcv)
try(setwd("~/Documents/Bristol/CHIELD/CHIELD_Online/processing/"))
d = read.csv("../data/db/CausalLinks.csv",stringsAsFactors = F)
dv1 = d[,c("Var1","bibref")]
dv2 = d[,c("Var2","bibref")]
names(dv2) = c("Var1",'bibref')
d = rbind(dv1,dv2)
cumUniqueVariables.mean = rep(0,length(unique(d$bibref)))
numSamples = 100
getCumUniqueVariables = function(){
docs = sample(unique(d$bibref))
d$bibref = factor(d$bibref,levels=docs)
d = d[order(d$bibref),]
# Cumulative unique variables
cumUniqueVariables =
sapply(docs,function(doc){
length(unique(d[1:max(which(d$bibref==doc)),]$Var1))
})
return(cumUniqueVariables)
}
cumUniqueVariables.mean = replicate(numSamples,getCumUniqueVariables())
cumUniqueVariables.mean = rowSums(cumUniqueVariables.mean)/numSamples
res = data.frame(
cumUniqueVariables.mean = cumUniqueVariables.mean,
numDocuments = 1:length(cumUniqueVariables.mean)
)
m0 = lm(cumUniqueVariables.mean~
numDocuments+
I(numDocuments^2),
data = res)
summary(m0)
newdata = data.frame(
numDocuments = 1:1000
)
predictedCurve = predict(m0,
newdata = data.frame(numDocuments = 1:3000))
dx = abs(diff(predictedCurve))
plateau = which(dx==min(dx))
newdata = data.frame(
numDocuments = seq(1,plateau,length.out=100)
)
predictedCurve = predict(m0,newdata = newdata)
plot(newdata$numDocuments,
predictedCurve,
xlab="Number of documents",
ylab="Number of unique variables",
type = 'l',
xlim=range(newdata$numDocuments),
ylim=c(0,max(predictedCurve)),
lty=2,col=2)
abline(0,1,lty=2)
points(1:length(cumUniqueVariables.mean),
cumUniqueVariables.mean,
xlab="Number of documents",
ylab="Number of unique variables",
type = 'l',lty=1,col=1,lwd=2)
plateau = which(dx==min(dx))
plateau
try(setwd("~/Documents/Bristol/CHIELD/CHIELD_Online/analysis//"))
d = read.csv("../data/db/Documents.csv",stringsAsFactors = F)
pdf("../../Graphs/analysis/NumDocumentsByYear.pdf",
width=6, height=4)
hist(d$year,
xlab="Year",
ylab="Number of documents",
main="")
dev.off()
min(d$year)
floor(d$year/10)
decades= range(floor(d$year/10)*10)
decades
decades= range(floor(d$year/10)*10)
hist(d$year,
xlab="Year",
ylab="Number of documents",
main="",
breaks=seq(decades[1],decades[2]+10,by=10))
try(setwd("~/Documents/Bristol/CHIELD/CHIELD_Online/analysis//"))
d = read.csv("../data/db/Documents.csv",stringsAsFactors = F)
decades= range(floor(d$year/10)*10)
pdf("../../Graphs/analysis/NumDocumentsByYear.pdf",
width=6, height=4)
hist(d$year,
xlab="Year",
ylab="Number of documents",
main="",
breaks=seq(decades[1],decades[2]+10,by=10))
dev.off()
summary(m0)
d = read.csv("../../data/FinalSignalData.csv")
```
Variable for length of first T1
```{r}
T1L = tapply(d[d$turnType=="T1",]$turnLength,
d[d$turnType=="T1",]$trialString, head, n=1)
d$T1Length = T1L[d$trialString]
d$T1Length[is.na(d$T1Length)] = mean(d$T1Length,na.rm=T)
d$T1Length.log = log(d$T1Length)
d$T1Length.log = d$T1Length.log - mean(d$T1Length.log)
head(d)
try(setwd("~/Documents/MPI/ViniciusMultimodal/multimodalCommunicationGame/experiment/analysis/R/"))
library(lme4)
library(sjPlot)
library(ggplot2)
library(lattice)
library(influence.ME)
library(dplyr)
```
The sjPlot library was updated during this investigation, removing various functions. They are reinstated here:
```{r}
sjp.lmer = plot_model
d = read.csv("../../data/FinalSignalData.csv")
T1L = tapply(d[d$turnType=="T1",]$turnLength,
d[d$turnType=="T1",]$trialString, head, n=1)
d$T1Length = T1L[d$trialString]
d$T1Length[is.na(d$T1Length)] = mean(d$T1Length,na.rm=T)
d$T1Length.log = log(d$T1Length)
d$T1Length.log = d$T1Length.log - mean(d$T1Length.log)
head(d)
table(d$modality)
---
title: "Modality effects in a signalling game"
output: pdf_document
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), "../../results/MainResults_Efficiency.pdf")) })
---
# Intro
The main data used in this analysis comes from `../../data/FinalSignalData.csv` (compiled by  `analyseData.R`).  Each row represents one signal, but this script only keeps one signal per trial, and the rest of the analysis is on the trial-by-trial level.  The variables in the data are as follows (some are calculated in the script below):
-  X: ID
-  filename: Filename of the ELAN file
-  dyadNumber: ID of the participant dyad
-  condition: Stimuli type (Auditory or Visual)
-  game: Game number (0-3)
-  trial: Trial number (0-15)
-  target: Target stimuli shown to the director
-  choice: Meaning chosen by the matcher
-  correct: True if the matcher's choice is correct
-  trialStart, trialEnd, trialLength: Start, end and length of trial in milliseconds
-  trialValue:  A unique string that represents data from the trial.  Numbers in the curly brackets represent the choices given to the matcher
-  startOfNextTrial: Timestamp for next trial, used in processing the data.
-  turnStart, turnEnd, turnLength: the start, end and length of the turn in milliseconds.
-  signalStart, signalEnd, signalLength: the start, end and length of the signal.
-  signalType:  Annotation value in ELAN, not meaningful
-  tiralString: Unique string to identify trial
-  modalityCondition:  The condition for the dyad (multi= multimodal, visual=gesture only, vocal=vocal only)
-  playerId:  Unique ID for the participant producing the signal
-  itemId:  Unique ID for the target stimulus
-  turnString:  Unque ID for the turn
-  matcherResponds:  Does matcher take a turn in this trial?
-  matcherResponds.cumulative: The (scaled) number of previous trials that a has responded.
-  T1Length, T1Length.log:  Length and log length of the director's first turn.
-  trialTotal: Number of trials played so far, scaled (and centered) to represent number of games played.
-  firstBlock:  Block order
-  incorrect:  Was the matcher's choice incorrect?
-  multimodal:  Was the director's first turn multimodal?
## Load libraries
```{r warning=FALSE, message=FALSE}
library(lme4)
library(sjPlot)
library(ggplot2)
library(lattice)
library(influence.ME)
library(dplyr)
```
The sjPlot library was updated during this investigation, removing various functions. They are reinstated here:
```{r}
sjp.lmer = plot_model
```
```{r echo=F}
try(setwd("~/Documents/MPI/ViniciusMultimodal/multimodalCommunicationGame/experiment/analysis/R/"))
```
## Load data
```{r}
d = read.csv("../../data/FinalSignalData.csv")
```
Variable for length of first T1
```{r}
T1L = tapply(d[d$turnType=="T1",]$turnLength,
d[d$turnType=="T1",]$trialString, head, n=1)
d$T1Length = T1L[d$trialString]
d$T1Length[is.na(d$T1Length)] = mean(d$T1Length,na.rm=T)
d$T1Length.log = log(d$T1Length)
d$T1Length.log = d$T1Length.log - mean(d$T1Length.log)
```
We don't need info on every signal in each turn, just the trial time.  Keep only 1st signal in each trial.
```{r}
d = d[!duplicated(d$trialString),]
```
# Descriptive stats
Make a variable to represent proportion of games played:
```{r}
# Make a variable that represents the number of trials played
d$trialTotal = d$trial + (d$game * (max(d$trial)+1))
# Convert to proportion of games played, so that estimates reflect change per game.
d$trialTotal = d$trialTotal / 16
```
Here is a graph showing the distribution of trial lengths by conditions:
```{r}
summary = d %>%
group_by(condition, modalityCondition,game) %>%
summarise(Efficiency=mean(trialLength),
sd=sd(trialLength),
ci.w =           qnorm(0.95)*sd/sqrt(length(trialLength)),
upper=Efficiency+ci.w,
lower = Efficiency-ci.w)
summary$game = summary$game +1
summary$modalityCondition =
factor(summary$modalityCondition,
levels = c("visual",'multi','vocal'),
labels=c("Gestural","Multimodal","Vocal"))
ggplot(d, aes(x=trialTotal, y=trialLength,colour=modalityCondition)) +
geom_smooth() + facet_grid(.~condition)
ggplot(d, aes(x=trialTotal, y=trialLength,colour=condition)) +
geom_smooth() + facet_grid(.~modalityCondition)
pd = position_dodge(width=0.5)
gx1 = ggplot(summary, aes(x=game, y=Efficiency, group=condition, colour=modalityCondition)) +
geom_errorbar(aes(ymin=lower, ymax=upper,group=modalityCondition), width=0.5,position=pd) +
facet_grid(. ~ condition) +
stat_summary(fun.y="mean", geom="line", aes(group=modalityCondition),position=pd) +
geom_point(aes(group=modalityCondition,shape=modalityCondition),position=pd) +
scale_colour_brewer(palette="Set2", name="Condition") +
scale_shape(name="Condition") +
theme(panel.grid.major.x = element_blank()) +
ggtitle("Efficiency") +
xlab("Game") +
ylab("Trial length (ms)")
gx1
pdf("../../results/graphs/Efficiency_gg.pdf",
width = 5, height=3)
gx1
dev.off()
gx2 = ggplot(summary, aes(x=game, y=Efficiency, group=condition, colour=condition, shape=condition)) +
geom_errorbar(aes(ymin=lower, ymax=upper), width=0.5) +
facet_grid(. ~ modalityCondition) +
stat_summary(fun.y="mean", geom="line", aes(group=condition)) +
geom_point() +
scale_colour_discrete(name="Stimuli") +
scale_shape_discrete(name="Stimuli") +
xlab("Game")
gx2
pdf("../../results/graphs/Efficiency_gg_alt.pdf",
width = 5, height=3)
gx2
dev.off()
```
![The efficiency of trials in different conditions](../../results/graphs/Efficiency.pdf)
Average trial time for the whole experiment:
```{r}
mean(d$trialLength)
sd(d$trialLength)
```
The distribution of trial times is very skewed:
```{r}
hist(d$trialLength)
```
So we transform it using a log transform, then center the data.
```{r}
d$trialLength.log = log(d$trialLength)
meanLogTrialLength = mean(d$trialLength.log)
d$trialLength.log = d$trialLength.log - meanLogTrialLength
hist(d$trialLength.log)
```
```{r}
# Center the trialTotal variable so intercept reflects after the first game
d$trialTotal = d$trialTotal - 2
matcherResponds.cumulative.mean = mean(d$matcherResponds.cumulative)
d$matcherResponds.cumulative = d$matcherResponds.cumulative - matcherResponds.cumulative.mean
d$matcherResponds = factor(d$matcherResponds)
```
Make a variable for which stimuli the players experienced first.
```{r}
firstBlock = tapply(as.character(d$condition),d$dyadNumber,head,n=1)
d$firstBlock = as.factor(firstBlock[match(d$dyadNumber,names(firstBlock))])
```
Reorder some levels so that the intercept reflects the most frequent condition.
```{r}
d$incorrect = !d$correct
```
Variable for whether T1 was a multimodal signal.
```{r}
turnD = read.csv("../../data/Final_Turn_data.csv")
turnD = turnD[turnD$turnType=="T1",]
turnD = turnD[turnD$role == "Director",]
d$multimodal = turnD[match(d$trialString, turnD$trialString),]$turnModalityType == "multi"
d$multimodal[is.na(d$multimodal)] = F
turnD = read.csv("../../data/Final_Turn_data.csv")
head(turnD)
table(turnD$modality)
table(turnD$numModalitiesUsed)
table(turnD$turnModalityType)
head(d)
head(turnD)
dx = d[d$turnString==t,]
t
t = unique(d$turnString)[1]
dx = d[d$turnString==t,]
turnD[turnD$turnString==dx$turnString,]
table(turnD$turnNumber)
table(turnD$turnNumber,turnD$turnModalityType)
262 + 4 + 1
